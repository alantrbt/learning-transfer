{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c4402f",
   "metadata": {},
   "source": [
    "# Reproduction des figures — Transferring Learning Trajectories of Neural Networks\n",
    "\n",
    "**Article** : Chijiwa et al. — arXiv:2305.14122v2  \n",
    "**Repo officiel** : `learning-transfer/`\n",
    "\n",
    "Ce notebook orchestre la reproduction des figures de l'article en utilisant le dépôt officiel de Daiki.\n",
    "\n",
    "## Pré-requis\n",
    "- GPU CUDA disponible\n",
    "- `torch`, `torchvision`, `pyyaml`, `pandas`, `matplotlib`, `scipy` installés\n",
    "- Être dans le répertoire `learning-transfer/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4a0e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /workspace\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# S'assurer qu'on est dans le bon répertoire\n",
    "REPO_ROOT = Path('/workspace') \n",
    "os.chdir(REPO_ROOT)\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "# Créer les répertoires nécessaires\n",
    "for d in ['__outputs__', '__data__', '__sync__']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "print(f'GPU available: {subprocess.run([sys.executable, \"-c\", \"import torch; print(torch.cuda.is_available())\"], capture_output=True, text=True).stdout.strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d165f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleEvaluater stub already exists\n",
      "PyTorch: 1.12.1+cu113\n",
      "TorchVision: 0.13.1+cu113\n",
      "CUDA: True (NVIDIA GeForce RTX 4070 Laptop GPU)\n"
     ]
    }
   ],
   "source": [
    "# Vérifier que le stub EnsembleEvaluater existe\n",
    "stub_path = REPO_ROOT / 'models' / 'ensemble_evaluater.py'\n",
    "if not stub_path.exists():\n",
    "    stub_path.write_text('class EnsembleEvaluater:\\n    pass\\n')\n",
    "    print('Created EnsembleEvaluater stub')\n",
    "else:\n",
    "    print('EnsembleEvaluater stub already exists')\n",
    "\n",
    "# Vérifier les imports critiques\n",
    "import torch\n",
    "import torchvision\n",
    "import yaml\n",
    "import scipy\n",
    "import matplotlib\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'TorchVision: {torchvision.__version__}')\n",
    "print(f'CUDA: {torch.cuda.is_available()} ({torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1e5ba",
   "metadata": {},
   "source": [
    "## Utilitaires\n",
    "\n",
    "Fonctions helper pour lancer les commandes et suivre la progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e858f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(command, exp_name, gpu_id=0, config='config.yaml', timeout=None):\n",
    "    \"\"\"Lance une commande exec_parallel.py et affiche la sortie en temps réel.\"\"\"\n",
    "    cmd = [\n",
    "        sys.executable, 'exec_parallel.py', command, exp_name,\n",
    "        '--gpu_id', str(gpu_id),\n",
    "        '--config', config\n",
    "    ]\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Running: {\" \".join(cmd)}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    start = time.time()\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(REPO_ROOT),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=timeout\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f'\\nCompleted in {elapsed:.1f}s (exit code: {result.returncode})')\n",
    "    \n",
    "    if result.stdout:\n",
    "        # Afficher les dernières lignes pertinentes\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        display_lines = lines[-30:] if len(lines) > 30 else lines\n",
    "        for line in display_lines:\n",
    "            print(f'  {line}')\n",
    "    \n",
    "    if result.returncode != 0 and result.stderr:\n",
    "        print(f'\\nSTDERR (last 20 lines):')\n",
    "        err_lines = result.stderr.strip().split('\\n')[-20:]\n",
    "        for line in err_lines:\n",
    "            print(f'  {line}')\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def check_outputs(exp_name, expected_count=None):\n",
    "    \"\"\"Vérifie les fichiers de sortie pour une expérience.\"\"\"\n",
    "    output_dir = REPO_ROOT / '__outputs__' / exp_name\n",
    "    if not output_dir.exists():\n",
    "        print(f'  No output directory for {exp_name}')\n",
    "        return []\n",
    "    \n",
    "    files = sorted(output_dir.iterdir())\n",
    "    json_files = [f for f in files if f.suffix == '.json' and 'transfer_results' in f.name]\n",
    "    pth_files = [f for f in files if f.suffix == '.pth']\n",
    "    \n",
    "    print(f'  {exp_name}: {len(pth_files)} checkpoints, {len(json_files)} transfer_results')\n",
    "    return json_files\n",
    "\n",
    "\n",
    "def run_train_until_complete(exp_name, gpu_id=0, max_retries=10):\n",
    "    \"\"\"Lance la commande train en boucle jusqu'à ce que tous les seeds soient complètes.\"\"\"\n",
    "    for i in range(max_retries):\n",
    "        print(f'\\n--- Train attempt {i+1}/{max_retries} for {exp_name} ---')\n",
    "        result = run_cmd('train', exp_name, gpu_id=gpu_id)\n",
    "        if 'all patterns are executed' in (result.stdout or ''):\n",
    "            print(f'All training seeds complete for {exp_name}')\n",
    "            return True\n",
    "    print(f'May need more retries for {exp_name}')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42136e92",
   "metadata": {},
   "source": [
    "---\n",
    "## Figure 5a — MNIST / MLP (Random Init → MNIST)\n",
    "\n",
    "C'est l'expérience la plus simple et la plus rapide (~30 min).\n",
    "\n",
    "### Étape 1 : Entraîner les modèles source/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c223d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train attempt 1/10 for mnist_mlp_sgd ---\n",
      "\n",
      "============================================================\n",
      "Running: /usr/bin/python3 exec_parallel.py train mnist_mlp_sgd --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 204.3s (exit code: 0)\n",
      "  Train Accuracy: 91.58888888888889\n",
      "  Val Accuracy: 90.95\n",
      "  [ 2026-02-11 15:29:13.282497 ] Epoch:  3\n",
      "  Train Accuracy: 91.75555555555556\n",
      "  Val Accuracy: 91.2\n",
      "  [ 2026-02-11 15:29:15.751270 ] Epoch:  4\n",
      "  Train Accuracy: 92.10000000000001\n",
      "  Val Accuracy: 91.23333333333333\n",
      "  [ 2026-02-11 15:29:18.218393 ] Epoch:  5\n",
      "  Train Accuracy: 92.08333333333333\n",
      "  Val Accuracy: 91.4\n",
      "  [ 2026-02-11 15:29:20.759098 ] Epoch:  6\n",
      "  Train Accuracy: 92.17222222222222\n",
      "  Val Accuracy: 91.03333333333333\n",
      "  [ 2026-02-11 15:29:23.275357 ] Epoch:  7\n",
      "  Train Accuracy: 92.1648148148148\n",
      "  Val Accuracy: 91.11666666666667\n",
      "  [ 2026-02-11 15:29:25.773527 ] Epoch:  8\n",
      "  Train Accuracy: 92.21851851851852\n",
      "  Val Accuracy: 90.9\n",
      "  [ 2026-02-11 15:29:28.217731 ] Epoch:  9\n",
      "  Train Accuracy: 92.17407407407407\n",
      "  Val Accuracy: 91.03333333333333\n",
      "  Number of available gpus:  1\n",
      "  Train/val dataset size: 60000\n",
      "  Train dataset size: 54000 , Val dataset size: 6000\n",
      "  /workspace/__outputs__/mnist_mlp_sgd/572d97c16b76d67bf9bd4c5aa18fbd92.mnist_mlp_sgd.pth\n",
      "  [ 2026-02-11 15:29:28.056830 ] Evaluate on Test Dataset...\n",
      "  Test Accuracy: 91.67999999999999\n",
      "  [ExecParallel] Stop searching because all patterns are executed\n",
      "All training seeds complete for mnist_mlp_sgd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner 6 seeds : [101, 102, 201, 202, 301, 302]\n",
    "# La commande itère aléatoirement sur la grille hparams_grid.\n",
    "# On la relance jusqu'à avoir couvert toutes les combinaisons.\n",
    "run_train_until_complete('mnist_mlp_sgd', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad737aae",
   "metadata": {},
   "source": [
    "### Étape 2 : Transférer les trajectoires\n",
    "\n",
    "4 méthodes : **GMT**, **FGMT**, **Naive** (noperm), **Oracle** (usetarget)\n",
    "\n",
    "Chaque commande transfer produit :\n",
    "- `transfer_results.json` — accuracies pendant le transfert (pour Fig 5a)\n",
    "- `ft_results.json` — accuracies pendant le fine-tuning (pour Fig 6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887a12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: /usr/bin/python3 exec_parallel.py transfer transfer_init-mnist_mlp --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 413.5s (exit code: 0)\n",
      "  [Learning Transfer:6/10] Val Accuracy: 75.08333333333333\n",
      "                        Matching Loss: tensor(42.1973, device='cuda:0')\n",
      "  [Learning Transfer:7/10] Val Accuracy: 85.16666666666667\n",
      "                        Matching Loss: tensor(55.4332, device='cuda:0')\n",
      "  [Learning Transfer:8/10] Val Accuracy: 83.15\n",
      "                        Matching Loss: tensor(44.9009, device='cuda:0')\n",
      "  [Learning Transfer:9/10] Val Accuracy: 84.71666666666667\n",
      "                        Matching Loss: tensor(48.1556, device='cuda:0')\n",
      "  [Learning Transfer:10/10] Val Accuracy: 82.25\n",
      "                        Matching Loss: tensor(54.9484, device='cuda:0')\n",
      "  [Learning Transfer] Final Val Accuracy: 82.25\n",
      "  val_accs: [62.983333333333334, 70.68333333333334, 80.30000000000001, 75.38333333333334, 74.28333333333333, 75.08333333333333, 85.16666666666667, 83.15, 84.71666666666667, 82.25]\n",
      "  Saved results at:\n",
      "    /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.transfer_results.json\n",
      "  Saved params at:\n",
      "    /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.params.pth\n",
      "  [ 2026-02-11 15:43:23.746909 ] Epoch:  0\n",
      "  Train Accuracy: 91.01851851851852\n",
      "  Val Accuracy: 91.2\n",
      "  [ 2026-02-11 15:43:26.182519 ] Epoch:  1\n",
      "  Train Accuracy: 91.66851851851851\n",
      "  Val Accuracy: 91.56666666666666\n",
      "  [ 2026-02-11 15:43:28.455644 ] Epoch:  2\n",
      "  Train Accuracy: 91.9074074074074\n",
      "  Val Accuracy: 91.06666666666666\n",
      "  Test Accuracy: 91.79\n",
      "  Saved ft results at: /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.ft_results.json\n",
      "  Saved ft model at: /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.ft_model.pth\n",
      "  \n",
      "  [ExecParallel] Stop searching because all patterns are executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/usr/bin/python3', 'exec_parallel.py', 'transfer', 'transfer_init-mnist_mlp', '--gpu_id', '0', '--config', 'config.yaml'], returncode=0, stdout=\"[DEBUG]\\n0.0\\n[DEBUG]\\n398.62231254577637\\n[DEBUG]\\n[ExecParallel] Start job: epoch_ft_3--lr_ft_0.01--gm_iters_1--checkpoint_epochs_[-1, 9]--num_splits_10--split_scheduling_fn_1+math.cos((t/T)*math.pi)--fast_perm_optim_False--source_target_seeds_[201, 202]--\\nPrefix: 2aaa3dcf2ab4ecb2e8df8e22ff53993a\\n[Sync] start: job_id= 1770824200.2163525\\n\\nckp_epochs: [-1, 9]\\n\\n[Learning Transfer:1/10] Val Accuracy: 57.56666666666666\\n                      Matching Loss: tensor(11.6997, device='cuda:0')\\n[Learning Transfer:2/10] Val Accuracy: 69.56666666666666\\n                      Matching Loss: tensor(20.1681, device='cuda:0')\\n[Learning Transfer:3/10] Val Accuracy: 71.85000000000001\\n                      Matching Loss: tensor(23.2758, device='cuda:0')\\n[Learning Transfer:4/10] Val Accuracy: 67.08333333333333\\n                      Matching Loss: tensor(30.0658, device='cuda:0')\\n[Learning Transfer:5/10] Val Accuracy: 68.91666666666667\\n                      Matching Loss: tensor(36.8650, device='cuda:0')\\n[Learning Transfer:6/10] Val Accuracy: 72.43333333333334\\n                      Matching Loss: tensor(43.6968, device='cuda:0')\\n[Learning Transfer:7/10] Val Accuracy: 80.03333333333333\\n                      Matching Loss: tensor(49.0585, device='cuda:0')\\n[Learning Transfer:8/10] Val Accuracy: 80.86666666666666\\n                      Matching Loss: tensor(52.0548, device='cuda:0')\\n[Learning Transfer:9/10] Val Accuracy: 79.55\\n                      Matching Loss: tensor(48.7951, device='cuda:0')\\n[Learning Transfer:10/10] Val Accuracy: 84.01666666666667\\n                      Matching Loss: tensor(61.6087, device='cuda:0')\\n[Learning Transfer] Final Val Accuracy: 84.01666666666667\\nval_accs: [57.56666666666666, 69.56666666666666, 71.85000000000001, 67.08333333333333, 68.91666666666667, 72.43333333333334, 80.03333333333333, 80.86666666666666, 79.55, 84.01666666666667]\\nSaved results at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/2aaa3dcf2ab4ecb2e8df8e22ff53993a.transfer_results.json\\nSaved params at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/2aaa3dcf2ab4ecb2e8df8e22ff53993a.params.pth\\n[ 2026-02-11 15:38:47.156258 ] Epoch:  0\\nTrain Accuracy: 90.92592592592592\\nVal Accuracy: 90.2\\n[ 2026-02-11 15:38:50.214747 ] Epoch:  1\\nTrain Accuracy: 91.64259259259259\\nVal Accuracy: 91.36666666666666\\n[ 2026-02-11 15:38:53.259378 ] Epoch:  2\\nTrain Accuracy: 91.82222222222222\\nVal Accuracy: 91.43333333333334\\nTest Accuracy: 91.61\\nSaved ft results at: /workspace/__outputs__/transfer_init-mnist_mlp/2aaa3dcf2ab4ecb2e8df8e22ff53993a.ft_results.json\\nSaved ft model at: /workspace/__outputs__/transfer_init-mnist_mlp/2aaa3dcf2ab4ecb2e8df8e22ff53993a.ft_model.pth\\n\\n[DEBUG]\\n[ExecParallel] Start job: epoch_ft_3--lr_ft_0.01--gm_iters_1--checkpoint_epochs_[-1, 9]--num_splits_10--split_scheduling_fn_1+math.cos((t/T)*math.pi)--fast_perm_optim_False--source_target_seeds_[101, 102]--\\nPrefix: f6b7d37f268588a0f5519753135dadc6\\n\\nckp_epochs: [-1, 9]\\n\\n[Learning Transfer:1/10] Val Accuracy: 67.06666666666666\\n                      Matching Loss: tensor(10.1650, device='cuda:0')\\n[Learning Transfer:2/10] Val Accuracy: 76.86666666666667\\n                      Matching Loss: tensor(19.6978, device='cuda:0')\\n[Learning Transfer:3/10] Val Accuracy: 78.58333333333334\\n                      Matching Loss: tensor(23.7912, device='cuda:0')\\n[Learning Transfer:4/10] Val Accuracy: 81.8\\n                      Matching Loss: tensor(29.1795, device='cuda:0')\\n[Learning Transfer:5/10] Val Accuracy: 81.65\\n                      Matching Loss: tensor(32.5183, device='cuda:0')\\n[Learning Transfer:6/10] Val Accuracy: 80.2\\n                      Matching Loss: tensor(37.2614, device='cuda:0')\\n[Learning Transfer:7/10] Val Accuracy: 76.03333333333333\\n                      Matching Loss: tensor(41.5556, device='cuda:0')\\n[Learning Transfer:8/10] Val Accuracy: 83.35000000000001\\n                      Matching Loss: tensor(55.7402, device='cuda:0')\\n[Learning Transfer:9/10] Val Accuracy: 80.18333333333332\\n                      Matching Loss: tensor(48.0660, device='cuda:0')\\n[Learning Transfer:10/10] Val Accuracy: 86.53333333333333\\n                      Matching Loss: tensor(64.6672, device='cuda:0')\\n[Learning Transfer] Final Val Accuracy: 86.53333333333333\\nval_accs: [67.06666666666666, 76.86666666666667, 78.58333333333334, 81.8, 81.65, 80.2, 76.03333333333333, 83.35000000000001, 80.18333333333332, 86.53333333333333]\\nSaved results at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/f6b7d37f268588a0f5519753135dadc6.transfer_results.json\\nSaved params at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/f6b7d37f268588a0f5519753135dadc6.params.pth\\n[ 2026-02-11 15:41:05.317398 ] Epoch:  0\\nTrain Accuracy: 91.0537037037037\\nVal Accuracy: 90.38333333333334\\n[ 2026-02-11 15:41:07.959391 ] Epoch:  1\\nTrain Accuracy: 91.78148148148149\\nVal Accuracy: 91.35\\n[ 2026-02-11 15:41:10.195595 ] Epoch:  2\\nTrain Accuracy: 91.80185185185185\\nVal Accuracy: 91.06666666666666\\nTest Accuracy: 91.34\\nSaved ft results at: /workspace/__outputs__/transfer_init-mnist_mlp/f6b7d37f268588a0f5519753135dadc6.ft_results.json\\nSaved ft model at: /workspace/__outputs__/transfer_init-mnist_mlp/f6b7d37f268588a0f5519753135dadc6.ft_model.pth\\n\\n[DEBUG]\\n0.2815999984741211\\n[DEBUG]\\n[ExecParallel] Start job: epoch_ft_3--lr_ft_0.01--gm_iters_1--checkpoint_epochs_[-1, 9]--num_splits_10--split_scheduling_fn_1+math.cos((t/T)*math.pi)--fast_perm_optim_False--source_target_seeds_[301, 302]--\\nPrefix: a11fbf945fa6ad693e5498160e3b61b7\\n\\nckp_epochs: [-1, 9]\\n\\n[Learning Transfer:1/10] Val Accuracy: 62.983333333333334\\n                      Matching Loss: tensor(11.4519, device='cuda:0')\\n[Learning Transfer:2/10] Val Accuracy: 70.68333333333334\\n                      Matching Loss: tensor(19.7071, device='cuda:0')\\n[Learning Transfer:3/10] Val Accuracy: 80.30000000000001\\n                      Matching Loss: tensor(24.5144, device='cuda:0')\\n[Learning Transfer:4/10] Val Accuracy: 75.38333333333334\\n                      Matching Loss: tensor(29.2347, device='cuda:0')\\n[Learning Transfer:5/10] Val Accuracy: 74.28333333333333\\n                      Matching Loss: tensor(33.4844, device='cuda:0')\\n[Learning Transfer:6/10] Val Accuracy: 75.08333333333333\\n                      Matching Loss: tensor(42.1973, device='cuda:0')\\n[Learning Transfer:7/10] Val Accuracy: 85.16666666666667\\n                      Matching Loss: tensor(55.4332, device='cuda:0')\\n[Learning Transfer:8/10] Val Accuracy: 83.15\\n                      Matching Loss: tensor(44.9009, device='cuda:0')\\n[Learning Transfer:9/10] Val Accuracy: 84.71666666666667\\n                      Matching Loss: tensor(48.1556, device='cuda:0')\\n[Learning Transfer:10/10] Val Accuracy: 82.25\\n                      Matching Loss: tensor(54.9484, device='cuda:0')\\n[Learning Transfer] Final Val Accuracy: 82.25\\nval_accs: [62.983333333333334, 70.68333333333334, 80.30000000000001, 75.38333333333334, 74.28333333333333, 75.08333333333333, 85.16666666666667, 83.15, 84.71666666666667, 82.25]\\nSaved results at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.transfer_results.json\\nSaved params at:\\n  /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.params.pth\\n[ 2026-02-11 15:43:23.746909 ] Epoch:  0\\nTrain Accuracy: 91.01851851851852\\nVal Accuracy: 91.2\\n[ 2026-02-11 15:43:26.182519 ] Epoch:  1\\nTrain Accuracy: 91.66851851851851\\nVal Accuracy: 91.56666666666666\\n[ 2026-02-11 15:43:28.455644 ] Epoch:  2\\nTrain Accuracy: 91.9074074074074\\nVal Accuracy: 91.06666666666666\\nTest Accuracy: 91.79\\nSaved ft results at: /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.ft_results.json\\nSaved ft model at: /workspace/__outputs__/transfer_init-mnist_mlp/a11fbf945fa6ad693e5498160e3b61b7.ft_model.pth\\n\\n[ExecParallel] Stop searching because all patterns are executed\\n\", stderr='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GMT Transfer\n",
    "run_cmd('transfer', 'transfer_init-mnist_mlp', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2886af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: /home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python exec_parallel.py transfer transfer_init-mnist_mlp_fast --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 2.8s (exit code: 1)\n",
      "\n",
      "STDERR (last 20 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\n",
      "      import commands\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\n",
      "      importlib.import_module('.' + module[:-3], package='commands')\n",
      "    File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\n",
      "      from commands.test import test\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\n",
      "      from models.image_classification import ImageClassification\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\n",
      "      from utils.subset_dataset import SubsetDataset, random_split\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\n",
      "      from torch._utils import _accumulate\n",
      "  ImportError: cannot import name '_accumulate' from 'torch._utils' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python', 'exec_parallel.py', 'transfer', 'transfer_init-mnist_mlp_fast', '--gpu_id', '0', '--config', 'config.yaml'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\\n    import commands\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\\n    importlib.import_module(\\'.\\' + module[:-3], package=\\'commands\\')\\n  File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\\n    from commands.test import test\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\\n    from models.image_classification import ImageClassification\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\\n    from utils.subset_dataset import SubsetDataset, random_split\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\\n    from torch._utils import _accumulate\\nImportError: cannot import name \\'_accumulate\\' from \\'torch._utils\\' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FGMT Transfer (version rapide)\n",
    "run_cmd('transfer', 'transfer_init-mnist_mlp_fast', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e978404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: /home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python exec_parallel.py transfer transfer_init-mnist_mlp_noperm --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 2.8s (exit code: 1)\n",
      "\n",
      "STDERR (last 20 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\n",
      "      import commands\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\n",
      "      importlib.import_module('.' + module[:-3], package='commands')\n",
      "    File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\n",
      "      from commands.test import test\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\n",
      "      from models.image_classification import ImageClassification\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\n",
      "      from utils.subset_dataset import SubsetDataset, random_split\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\n",
      "      from torch._utils import _accumulate\n",
      "  ImportError: cannot import name '_accumulate' from 'torch._utils' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python', 'exec_parallel.py', 'transfer', 'transfer_init-mnist_mlp_noperm', '--gpu_id', '0', '--config', 'config.yaml'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\\n    import commands\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\\n    importlib.import_module(\\'.\\' + module[:-3], package=\\'commands\\')\\n  File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\\n    from commands.test import test\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\\n    from models.image_classification import ImageClassification\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\\n    from utils.subset_dataset import SubsetDataset, random_split\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\\n    from torch._utils import _accumulate\\nImportError: cannot import name \\'_accumulate\\' from \\'torch._utils\\' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Transfer (pas de permutation)\n",
    "run_cmd('transfer', 'transfer_init-mnist_mlp_noperm', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f8f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: /home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python exec_parallel.py transfer transfer_init-mnist_mlp_usetarget --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 2.7s (exit code: 1)\n",
      "\n",
      "STDERR (last 20 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\n",
      "      import commands\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\n",
      "      importlib.import_module('.' + module[:-3], package='commands')\n",
      "    File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\n",
      "      from commands.test import test\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\n",
      "      from models.image_classification import ImageClassification\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\n",
      "      from utils.subset_dataset import SubsetDataset, random_split\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\n",
      "      from torch._utils import _accumulate\n",
      "  ImportError: cannot import name '_accumulate' from 'torch._utils' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python', 'exec_parallel.py', 'transfer', 'transfer_init-mnist_mlp_usetarget', '--gpu_id', '0', '--config', 'config.yaml'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\\n    import commands\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\\n    importlib.import_module(\\'.\\' + module[:-3], package=\\'commands\\')\\n  File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\\n    from commands.test import test\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\\n    from models.image_classification import ImageClassification\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\\n    from utils.subset_dataset import SubsetDataset, random_split\\n  File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\\n    from torch._utils import _accumulate\\nImportError: cannot import name \\'_accumulate\\' from \\'torch._utils\\' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oracle Transfer (utilise la vraie trajectoire cible)\n",
    "run_cmd('transfer', 'transfer_init-mnist_mlp_usetarget', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12220da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No output directory for transfer_init-mnist_mlp\n",
      "  No output directory for transfer_init-mnist_mlp_fast\n",
      "  No output directory for transfer_init-mnist_mlp_noperm\n",
      "  No output directory for transfer_init-mnist_mlp_usetarget\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les résultats produits\n",
    "for exp in ['transfer_init-mnist_mlp', 'transfer_init-mnist_mlp_fast',\n",
    "            'transfer_init-mnist_mlp_noperm', 'transfer_init-mnist_mlp_usetarget']:\n",
    "    check_outputs(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cbfa7",
   "metadata": {},
   "source": [
    "### Étape 3 : Générer la figure PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: /home/alan/miniconda3/envs/transferring-learning-trajectories/bin/python exec_parallel.py plot section_4_1_mnist_mlp --gpu_id 0 --config config.yaml\n",
      "============================================================\n",
      "\n",
      "Completed in 2.8s (exit code: 1)\n",
      "\n",
      "STDERR (last 20 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/exec_parallel.py\", line 16, in <module>\n",
      "      import commands\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/__init__.py\", line 7, in <module>\n",
      "      importlib.import_module('.' + module[:-3], package='commands')\n",
      "    File \"/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/train.py\", line 10, in <module>\n",
      "      from commands.test import test\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/commands/test.py\", line 13, in <module>\n",
      "      from models.image_classification import ImageClassification\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/models/image_classification.py\", line 10, in <module>\n",
      "      from utils.subset_dataset import SubsetDataset, random_split\n",
      "    File \"/home/alan/Transferring_Learning_Trajectories_of_NN/learning-transfer/utils/subset_dataset.py\", line 3, in <module>\n",
      "      from torch._utils import _accumulate\n",
      "  ImportError: cannot import name '_accumulate' from 'torch._utils' (/home/alan/miniconda3/envs/transferring-learning-trajectories/lib/python3.11/site-packages/torch/_utils.py)\n",
      "\n",
      "⚠️ PDF non trouvé — vérifier les logs ci-dessus\n"
     ]
    }
   ],
   "source": [
    "result = run_cmd('plot', 'section_4_1_mnist_mlp', gpu_id=0)\n",
    "\n",
    "# Trouver et afficher le PDF généré\n",
    "import glob\n",
    "pdfs = glob.glob(str(REPO_ROOT / '__outputs__' / '**' / '*section_4-1*mnist*.pdf'), recursive=True)\n",
    "if pdfs:\n",
    "    print(f'\\nFigure générée : {pdfs[0]}')\n",
    "else:\n",
    "    print('\\nPDF non trouvé — vérifier les logs ci-dessus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8aa67e",
   "metadata": {},
   "source": [
    "### Afficher la figure générée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ec931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Chercher le PDF ou le convertir en PNG pour l'affichage\n",
    "pdfs = glob.glob(str(REPO_ROOT / '__outputs__' / '**' / '*section_4-1*mnist*.pdf'), recursive=True)\n",
    "if pdfs:\n",
    "    # Convertir le PDF en PNG pour l'affichage dans le notebook\n",
    "    pdf_path = pdfs[0]\n",
    "    png_path = pdf_path.replace('.pdf', '.png')\n",
    "    try:\n",
    "        subprocess.run(['pdftoppm', '-png', '-r', '150', '-singlefile', pdf_path, png_path.replace('.png', '')],\n",
    "                      check=True, capture_output=True)\n",
    "        display(Image(filename=png_path, width=500))\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        print(f'PDF sauvegardé à : {pdf_path}')\n",
    "        print('(Installer poppler-utils pour afficher dans le notebook : sudo apt install poppler-utils)')\n",
    "else:\n",
    "    print('Aucune figure trouvée. Exécutez les cellules précédentes d\\'abord.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f99e91",
   "metadata": {},
   "source": [
    "---\n",
    "## Figure 5b — CIFAR-10 / Conv8 (Random Init → CIFAR-10)\n",
    "\n",
    "**Temps estimé** : ~2-3h sur GPU  \n",
    "**Dataset** : CIFAR-10 (téléchargement automatique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee08ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner les modèles Conv8 (9 seeds, 60 epochs chacun)\n",
    "run_train_until_complete('cifar10_conv8_sgd', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 variantes de transfert\n",
    "for variant in ['transfer_init-cifar10_conv8',\n",
    "                'transfer_init-cifar10_conv8_fast',\n",
    "                'transfer_init-cifar10_conv8_noperm',\n",
    "                'transfer_init-cifar10_conv8_usetarget']:\n",
    "    run_cmd('transfer', variant, gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer la figure\n",
    "run_cmd('plot', 'section_4_1_cifar10_conv8', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea2e64",
   "metadata": {},
   "source": [
    "---\n",
    "## Figure 5f — CIFAR-10 → CIFAR-100 / Conv8 (Pretrained Init)\n",
    "\n",
    "**Pré-requis** : `cifar10_conv8_sgd` entraîné (cellule précédente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuner sur CIFAR-100 split1 à partir des modèles CIFAR-10 pré-entraînés\n",
    "run_train_until_complete('cifar10_to_cifar100-1_conv8_sgd', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['transfer_cifar10-cifar100_conv8',\n",
    "                'transfer_cifar10-cifar100_conv8_fast',\n",
    "                'transfer_cifar10-cifar100_conv8_noperm',\n",
    "                'transfer_cifar10-cifar100_conv8_usetarget']:\n",
    "    run_cmd('transfer', variant, gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69afa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmd('plot', 'section_4_1_cifar10_cifar100_conv8', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e40fc3",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3.3 — Ablations (Linear vs Actual, Uniform vs Cosine)\n",
    "\n",
    "**Pré-requis** : `cifar10_conv8_sgd` entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation : scheduling uniforme vs cosinus\n",
    "run_cmd('transfer', 'transfer_init-cifar10_conv8_ablation_scheduling_uniform', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation : trajectoire linéaire vs fine-grained (checkpoints réels)\n",
    "for variant in ['transfer_init-cifar10_conv8_ablation_linear',\n",
    "                'transfer_init-cifar10_conv8_ablation_linear_fast',\n",
    "                'transfer_init-cifar10_conv8_ablation_finegrained',\n",
    "                'transfer_init-cifar10_conv8_ablation_finegrained_fast']:\n",
    "    run_cmd('transfer', variant, gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df801c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer les figures d'ablation\n",
    "run_cmd('plot', 'section_3_3_uniform_vs_cosine', gpu_id=0)\n",
    "run_cmd('plot', 'section_3_3_real_vs_linear', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348edce9",
   "metadata": {},
   "source": [
    "---\n",
    "## Figures 6a-b — Fine-tuning (Section 4.2)\n",
    "\n",
    "Les résultats `ft_results.json` sont produits automatiquement lors du transfert. Il suffit de tracer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb82a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6a : CIFAR-10 Conv8 fine-tuning\n",
    "run_cmd('plot', 'section_4_2_cifar10_conv8', gpu_id=0)\n",
    "\n",
    "# Figure 6b : CIFAR-10 → CIFAR-100 Conv8 fine-tuning  \n",
    "run_cmd('plot', 'section_4_2_cifar10_cifar100_conv8', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34455995",
   "metadata": {},
   "source": [
    "---\n",
    "## Figure 7 — Loss Landscape (Section 4.3)\n",
    "\n",
    "Visualisation 1D (linear mode connectivity) et 2D (heatmap) de la loss landscape.\n",
    "\n",
    "**Attention** : Ce script est GPU-intensif car il évalue des modèles interpolés en direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmd('plot', 'section_4_3_cifar10_conv8', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd12f4",
   "metadata": {},
   "source": [
    "---\n",
    "## Figures ImageNet (nécessitent ImageNet téléchargé)\n",
    "\n",
    "### Pré-requis\n",
    "- **ImageNet ILSVRC2012** (~150 GB) dans `__data__/imagenet/{train,val}/`\n",
    "- **Stanford Cars** dans `__data__/`\n",
    "- **CUB-200-2011** dans `__data__/`\n",
    "\n",
    "### Temps de calcul\n",
    "- Entraînement ResNet-18 × 6 seeds : **~3-7 jours** sur 1 GPU A100\n",
    "- Fine-tuning Cars/CUB × 6 seeds : **~6-12h** après les modèles ImageNet\n",
    "\n",
    "Décommenter les cellules ci-dessous si les datasets sont disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DÉCOMMENTER SI IMAGENET EST DISPONIBLE ===\n",
    "\n",
    "# # Figure 5c : ImageNet / ResNet-18\n",
    "# run_train_until_complete('imagenet_resnet18_sgd', gpu_id=0)\n",
    "# for v in ['transfer_init-imagenet_resnet18', 'transfer_init-imagenet_resnet18_fast',\n",
    "#           'transfer_init-imagenet_resnet18_noperm', 'transfer_init-imagenet_resnet18_usetarget']:\n",
    "#     run_cmd('transfer', v, gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_1_imagenet_resnet18', gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_2_imagenet_resnet18', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a381c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DÉCOMMENTER SI IMAGENET + CARS SONT DISPONIBLES ===\n",
    "\n",
    "# # Figure 5d : ImageNet → Cars\n",
    "# run_train_until_complete('imagenet_to_cars_resnet18_sgd', gpu_id=0)\n",
    "# for v in ['transfer_imagenet-cars_resnet18', 'transfer_imagenet-cars_resnet18_fast',\n",
    "#           'transfer_imagenet-cars_resnet18_noperm', 'transfer_imagenet-cars_resnet18_usetarget']:\n",
    "#     run_cmd('transfer', v, gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_1_imagenet_cars_resnet18', gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_2_imagenet_cars_resnet18', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DÉCOMMENTER SI IMAGENET + CUB SONT DISPONIBLES ===\n",
    "\n",
    "# # Figure 5e : ImageNet → CUB\n",
    "# run_train_until_complete('imagenet_to_cub_resnet18_sgd', gpu_id=0)\n",
    "# for v in ['transfer_imagenet-cub_resnet18', 'transfer_imagenet-cub_resnet18_fast',\n",
    "#           'transfer_imagenet-cub_resnet18_noperm', 'transfer_imagenet-cub_resnet18_usetarget']:\n",
    "#     run_cmd('transfer', v, gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_1_imagenet_cub_resnet18', gpu_id=0)\n",
    "# run_cmd('plot', 'section_4_2_imagenet_cub_resnet18', gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a9f9f",
   "metadata": {},
   "source": [
    "---\n",
    "## Résumé des figures générées\n",
    "\n",
    "Lister toutes les figures PDF produites dans `__outputs__/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09662b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_pdfs = sorted(glob.glob(str(REPO_ROOT / '__outputs__' / '**' / '*.pdf'), recursive=True))\n",
    "\n",
    "if all_pdfs:\n",
    "    print(f'✅ {len(all_pdfs)} figure(s) PDF générée(s) :\\n')\n",
    "    for pdf in all_pdfs:\n",
    "        rel = os.path.relpath(pdf, REPO_ROOT)\n",
    "        size_kb = os.path.getsize(pdf) / 1024\n",
    "        print(f'  {rel}  ({size_kb:.1f} KB)')\n",
    "else:\n",
    "    print('❌ Aucune figure PDF trouvée. Exécutez les cellules de pipeline ci-dessus.')\n",
    "\n",
    "print('\\n--- Comparaison avec les figures originales ---')\n",
    "original_pdfs = sorted(glob.glob(str(REPO_ROOT.parent / 'arXiv-2305.14122v2' / 'resources' / '*.pdf')))\n",
    "print(f'{len(original_pdfs)} PDFs originaux dans arXiv-2305.14122v2/resources/')\n",
    "for pdf in original_pdfs:\n",
    "    print(f'  {os.path.basename(pdf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4061a2a",
   "metadata": {},
   "source": [
    "---\n",
    "## Correspondance Figures de l'article ↔ Commandes\n",
    "\n",
    "| Figure | Section | Commande plot | Dataset nécessaire |\n",
    "|--------|---------|---------------|-------------------|\n",
    "| **Fig 1-2** | Intro | Diagrammes conceptuels (TikZ) | — |\n",
    "| **Fig 3a-c** | 3.2 | PDFs pré-fournis dans `resources/` | — |\n",
    "| **Fig 4** | 3.3 | `section_3_3_real_vs_linear` + `section_3_3_uniform_vs_cosine` | CIFAR-10 |\n",
    "| **Fig 5a** | 4.1 | `section_4_1_mnist_mlp` | MNIST |\n",
    "| **Fig 5b** | 4.1 | `section_4_1_cifar10_conv8` | CIFAR-10 |\n",
    "| **Fig 5c** | 4.1 | `section_4_1_imagenet_resnet18` | ImageNet |\n",
    "| **Fig 5d** | 4.1 | `section_4_1_imagenet_cars_resnet18` | ImageNet + Cars |\n",
    "| **Fig 5e** | 4.1 | `section_4_1_imagenet_cub_resnet18` | ImageNet + CUB |\n",
    "| **Fig 5f** | 4.1 | `section_4_1_cifar10_cifar100_conv8` | CIFAR-10 + CIFAR-100 |\n",
    "| **Fig 6a** | 4.2 | `section_4_2_cifar10_conv8` | CIFAR-10 |\n",
    "| **Fig 6b** | 4.2 | `section_4_2_cifar10_cifar100_conv8` | CIFAR-10/100 |\n",
    "| **Fig 6c** | 4.2 | `section_4_2_imagenet_cars_resnet18` | ImageNet + Cars |\n",
    "| **Fig 6d** | 4.2 | `section_4_2_imagenet_cub_resnet18` | ImageNet + CUB |\n",
    "| **Fig 7** | 4.3 | `section_4_3_cifar10_conv8` | CIFAR-10 |\n",
    "| **Fig 8** | 4.3 | Pas de script dédié | ImageNet + Cars/CUB |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
